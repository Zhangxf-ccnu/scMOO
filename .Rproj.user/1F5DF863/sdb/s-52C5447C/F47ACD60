{
    "collab_server" : "",
    "contents" : "#' use scMOO to impute dropout values in scRNA-seq data\n#'\n#' @param Y_count An expression count matrix. The rows correspond to genes and\n#' the columns correspond to cells. Can be sparse.\n#'\n#' @param W W_{gc} is set to the ratio of the number of non-zero elements in Y to the number\n#' of zero elements in Y if Y_{gc} = 0, and to 1 otherwise.\n#'\n#' @param k The rank of the low-rank approximation matrix.\n#'\n#' @param q The parameter for number of additional power iterations.\n#'\n#' @param percent The expression count matrix is preprocessed by filtering out the genes\n#' expressed in at most percent*\\eqn{100\\%} of the cells.\n#'\n#' @param lambda1 Tuning parameter for entropy regularizer.\n#'\n#' @param lambda2 Tuning parameter to facilitate feature selection and regularization.\n#'\n#' @param lambda3 Tuning parameter to penalize the diagonal elements of the parameter to\n#' eliminate the trivial solution of representing an expression level as a linear combination\n#' of itself.\n#'\n#' @param alpha Tuning parameter to balance the error between the imputed and\n#' observed data and the error of model fitting data.\n#'\n#' @param MAX_ITER Maximum iteration of scMOO.\n#'\n#' @param ABSTOL Absolute tolerance of circulation.\n#'\n#' @param learning_rate A hyper-parameter that controls the speed of adjusting the weights of the network\n#' with respect to the loss gradient.\n#'\n#' @param epochs The number of the entire training set going through the entire network.\n#'\n#' @param verbose Whether to output the value of metrics at the end of each epoch. Default is TRUE.\n#'\n#'\n#'\n#' @return If `estimates.only = TRUE', then a matrix of scMOO estimates.\n#'\n#' If `estimates.only = FALSE', a list with the following components\n#'\n#' \\item{\\code{estimate}}{Recovered (normalized) expression.}\n#'\n#' \\item{\\code{size.factor}}{Size factor used for normalization.}\n#'\n#' \\item{\\code{pred.time}}{Total time for scMOO estimation.}\n#'\n#' \\item{\\code{alpha}}{Tuning parameter to balance the error between the imputed and\n#' observed data and the error of model fitting data.}\n#'\n#' \\item{\\code{w}}{The combination weights W1, W2 and W3.}\n#'\n#'\n#' @export\n#'\n#'\n#' @import keras\n#'\n#' @import tensorflow\n#'\n#' @import rsvd\n#'\n#' @author Ke Jin, \\email{kej13@mails.ccnu.edu.cn}\n#'\n#' @examples\n#'\n#' data(\"PBMC_CL\")\n#'\n#' result <- scMOO(PBMC_CL, percent = 0, estimates.only = TRUE)\n#'\nscMOO <- function(Y.count, W=NULL, K=0, q=10, percent = 0.05,\n\n                lambda1=NULL, lambda2=NULL, lambda3=1e10, alpha=NULL,\n\n                MAX.ITER = 4, ABSTOL = 1e-3, learning.rate = 0.0001,\n\n                epochs = 100, verbose = TRUE, estimates.only = FALSE){\n\n\n  # calculating the tunning parameter lambda\n\n  if (is.null(lambda2)) {\n\n    message(\"Calculating the penalty parameter in the lasso models ...\")\n\n    lambda2 <- calc.lambda(Y.count, percent)\n\n    message(\"Done!\")\n\n  }\n\n\n  # preprocessing and log-normalization\n\n  message(\"Starting preprocessing and log-normalization ...\")\n\n  Y <- log.normalization(Y.count, percent, preprocess.only = FALSE)\n\n  Y.count <- log.normalization(Y.count, percent, preprocess.only = TRUE)\n\n  message(\"Done!\")\n\n\n  # compute weights\n  if (is.null(W)) {\n\n    m = nrow(Y)\n    n = ncol(Y)\n\n    W <- matrix(1, m, n)\n    rate <- round(sum(Y!=0)/sum(Y==0), 2)\n\n    W[Y==0] <- rate\n  }\n\n\n  Y.count <- clean.data(Y.count)\n\n  ngenes <- nrow(Y.count)\n\n  ncells <- ncol(Y.count)\n\n  gene.names <- rownames(Y.count)\n\n  cell.names <- colnames(Y.count)\n\n\n  # assign size factor\n\n  sf.out <- calc.size.factor(Y.count)\n\n  sf <- sf.out[[1]]\n\n  scale.sf <- sf.out[[2]]\n\n\n\n  result <- list()\n\n  result$size.factor <- scale.sf*sf\n\n\n\n  message(\"Imputation starts ...\")\n\n  message(\"iter\", ' objective')\n\n  pred.st <- Sys.time()\n\n  k <- 1\n\n  history.objval <- c()\n\n\n  # initialize X\n  X <- Y\n\n\n  batch.size <- nrow(Y)\n\n  B <- keras_lasso_regression(X, Y, epochs = epochs, batch_size = batch.size, lambda1=lambda2, lambda2=lambda3,\n\n                              learning_rate = learning.rate, verbose = verbose)\n\n  batch.size <- ncol(Y)\n\n  A <- t(keras_lasso_regression(t(X), t(Y), epochs = epochs, batch_size = batch.size, lambda1 = lambda2, lambda2 = lambda3,\n\n                                learning_rate = learning.rate, verbose = verbose))\n\n  if ( K ==0 ) {\n    k_choice <- choose_k(t(X))\n    K <-  k_choice$k\n    cat(sprintf(\"Chose K=%d\\n\",K))\n  }\n\n  cat(\"Randomized SVD\\n\")\n  fastDecomp_noc <- randomized.svd(t(X),K,q=q)\n\n  X_rank_k <- fastDecomp_noc$u[,1:K]%*%diag(fastDecomp_noc$d[1:K])%*% t(fastDecomp_noc$v[,1:K])\n\n  X_rank_k[X_rank_k<0]=0\n\n  ########\n  AY <- A%*%Y\n  YB <- Y%*%B\n\n\n  X <- ( 0.5*W^2*Y + 0.5*(1/3*pmax(AY,0)+1/3*pmax(YB,0)+1/3*t(X_rank_k)) )/ (0.5*W^2+0.5)\n\n\n  message(\"Calculating the tuning parameter alpha ...\")\n  if (is.null(alpha)) {\n\n    alpha <- norm(W*(X-Y), 'F')^2/(1/3*norm(X-AY, 'F')^2 + 1/3*norm(X-YB, 'F')^2\n                                   + 1/3*norm(X-t(X_rank_k), 'F')^2 + norm(W*(X-Y), 'F')^2)\n  }\n\n\n  if (is.null(lambda1)) {\n\n    message(\"Calculating the tuning parameter for entropy regularizer ...\")\n\n    lambda1 <- alpha * mean( norm(X-AY, 'F')^2, norm(X-YB, 'F')^2,\n                             norm(X-t(X_rank_k), 'F')^2)/(ngenes*ncells)\n\n    message(\"Done!\")\n\n  }\n\n\n  while (k <= MAX.ITER){\n\n\n    batch.size <- nrow(Y)\n\n\n    # using keras with SGD algorithm to calculate B or A\n\n    B <- keras_lasso_regression(Y=X, X=Y, epochs = epochs, batch_size = batch.size, lambda1=lambda2, lambda2=lambda3,\n\n                                learning_rate = learning.rate, verbose = verbose)\n\n\n    batch.size = ncol(Y)\n\n    A <- t(keras_lasso_regression(Y=t(X), X=t(Y), epochs = epochs, batch_size = batch.size, lambda1 = lambda2, lambda2 = lambda3,\n\n                                  learning_rate = learning.rate, verbose = verbose))\n\n\n    # calculating the low-rank approximation\n    k_choice <- choose_k(t(X))\n    K <-  k_choice$k\n    cat(sprintf(\"Chose K=%d\\n\",K))\n\n\n    cat(\"Randomized SVD\\n\")\n    fastDecomp_noc <- randomized.svd(t(X),K,q=q)\n\n    X_rank_k <- fastDecomp_noc$u[,1:K]%*%diag(fastDecomp_noc$d[1:K])%*% t(fastDecomp_noc$v[,1:K])\n\n    X_rank_k[X_rank_k<0]=0\n\n\n    # compute W1, W2 ,W3\n    AY <- A%*%Y\n    YB <- Y%*%B\n\n    N1 <- alpha*norm(X-AY, 'F')^2/(lambda1*ngenes*ncells)\n    N2 <- alpha*norm(X-YB, 'F')^2/(lambda1*ngenes*ncells)\n    N3 <- alpha*norm(X-t(X_rank_k), 'F')^2/(lambda1*ngenes*ncells)\n\n    W_sum <- sum(exp(-N1), exp(-N2), exp(-N3))\n    W1 <- exp(-N1)/W_sum\n    W2 <- exp(-N2)/W_sum\n    W3 <- exp(-N3)/W_sum\n    cat(sprintf(\"W1=%.4f\\n\",W1))\n    cat(sprintf(\"W2=%.4f\\n\",W2))\n    cat(sprintf(\"W3=%.4f\\n\",W3))\n\n\n    X <- ( (1-alpha)*W^2*Y + alpha*(W1*AY + W2*YB + W3*t(X_rank_k)) )/ ((1-alpha)*W^2 + alpha)\n\n\n    history.objval[k] <- objective(W=W, W1=W1, W2=W2, W3=W3, alpha=alpha, X=X, Y=Y, AY=AY, YB=YB,\n                                    A=A, B=B, X_rank_k=X_rank_k, lambda1=lambda1, lambda2=lambda2)\n\n\n    message(k, '    ', round(history.objval[k], 3))\n\n    if (k > 1 && abs(history.objval[k] - history.objval[k-1]) < ABSTOL) break\n\n    k <- k + 1\n\n\n\n  }\n\n\n\n  Xhat <- pmax(X, 0)\n\n\n\n  obj.prior <- history.objval\n\n\n  pred.time <- Sys.time() - pred.st\n\n\n  result$estimate <- exp(Xhat)-1\n\n\n  result$pred.time <- pred.time\n\n  result$alpha <- alpha\n\n  result$w <- c(W1, W2, W3)\n\n  message(\"Done!\")\n\n  message(\"Finish time: \", Sys.time())\n\n  message(\"Total time: \", format(result$pred.time))\n\n  if (!estimates.only) {\n\n    class(result) <- \"scMOO\"\n\n    result\n\n  } else {\n\n    result$estimate\n\n  }\n\n  class(result) <- \"scMOO\"\n\n  result\n\n}\n",
    "created" : 1639052028001.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1402070101",
    "id" : "F47ACD60",
    "lastKnownWriteTime" : 1639042344,
    "last_content_update" : 1639042344,
    "path" : "~/Desktop/scMOO/R/scMOO.R",
    "project_path" : "R/scMOO.R",
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}